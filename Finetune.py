# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wvYa_NqkWYo3jsVcAM9ry1aZk8TtheR1
"""

import tensorflow as tf
from tensorflow.keras.applications import vgg16
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import cv2
import numpy as np
import os
from tqdm import tqdm
import matplotlib.pyplot as plt

"""# Unzip the dataset
from zipfile import ZipFile

file_name = "ultrasound-breast-images-for-breast-cancer.zip"
with ZipFile(file_name, 'r') as zip:
    zip.extractall()
    print('Dataset extraction done.')
"""
# Load and preprocess the images
X = []
y = []

train_dir = 'ultrasound breast classification/train'
val_dir = 'ultrasound breast classification/val'

for folder in tqdm(os.listdir(train_dir)):
    if folder == 'benign':
        label = 0  # benign class label
    else:
        label = 1  # malignant class label

    folder_path = os.path.join(train_dir, folder)
    for file in os.listdir(folder_path):
        img = cv2.imread(os.path.join(folder_path, file))
        img = cv2.resize(img, (224, 224))
        X.append(img)
        y.append(label)

for folder in tqdm(os.listdir(val_dir)):
    if folder == 'benign':
        label = 0  # benign class label
    else:
        label = 1  # malignant class label

    folder_path = os.path.join(val_dir, folder)
    for file in os.listdir(folder_path):
        img = cv2.imread(os.path.join(folder_path, file))
        img = cv2.resize(img, (224, 224))
        X.append(img)
        y.append(label)

# Convert the data to NumPy arrays
X = np.array(X)
y = np.array(y)

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

from sklearn.utils import shuffle

batch_size = 32  # Define the batch size

# Shuffle the training data
X_train, y_train = shuffle(X_train, y_train, random_state=42)

"""# Normalize the pixel values in batches for X_train
for i in range(0, len(X_train), batch_size):
    batch = X_train[i:i + batch_size] / 255.0
    X_train[i:i + batch_size] = batch
# Normalize the pixel values in batches for X_test
for i in range(0, len(X_test), batch_size):
    batch = X_test[i:i + batch_size] / 255.0
    X_test[i:i + batch_size] = batch
"""
# Convert the labels to categorical format
y_train = to_categorical(y_train, num_classes=2)
y_test = to_categorical(y_test, num_classes=2)

# Load the pre-trained VGG16 model
base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add custom layers on top of the VGG16 base model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the base layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
# history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))
history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))

# Save the transfer learning model
model.save('Trained/FreshTrained.h5')


"""# Plot the training and validation accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()
"""
